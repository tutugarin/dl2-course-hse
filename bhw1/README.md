# Отчет по БДЗ#1 от Ершова Ивана (tutugarin) 

В рамках данного домашнего задания нужно было обучить модель для генерации рассказов и сравнить полученную модель с `GPT2-XL`

## Список файлов:

В этом разделе описаны файлы, которые будут представлены для сдачи, и краткое описание каждого из файла. Подробное описание каждого из файла будет далее.

1. `dataset.py` -- токенайзер, датасет, парсинг данных, даталоадер, полезные функции для работы с данными
1. `model.py` -- опеределение модели
1. `train.py` -- функции для обучения и валидации
1. `utils.py` -- некоторые утилити функции и конфигурация обучения
1. `main.py` -- скрипт для запуска обучения
1. `inference.py` -- скрипт для удобной генерации текста
1. `checkpoint_best.pt` -- лучшая модель, здесь сохранена модель, оптимизатор, лучший лосс, списки из тренировочных и валидационных лосов
1. `training_logs` -- все логи обучения


## Описание содержания файлов:

### `dataset.py`

Краткое описание имеющихся функций и классов:

- `Tokenizer` -- токенайзер, который на вход принимает `.txt` файл со всеми текстами (формат файла: на каждой строчке новый рассказ). Если до этого не был создан токенизатор, то создается `SentencePieceProcessor`, иначе загружает `SentencePieceProcessor` из файла. Используется `Byte-Pair Encoding tokenization`, размер словаря `5120`. `Tokenizer` так же определяет методы, которые кодируют предложения в последовательности токетонв и декодирует токены в предложения

- `TextDataset` -- датасет, который наследуется от `torch.utils.data.Dataset`. На вход принимается файл со всеми текстами, они токенизируются и сохраняются в поле класса. В методе `__getitem__`, которые принимает на вход индекс, происходит добавление `<bos>` и `<eos>` токенов. Также, если длина исходной последовательности токенов превышает `max_lex - 2`, то последовательность обезается до `max_lex - 2` токенов. Длинных предложений в исходном датасете немного, поэтому такой подход некритично мешает обучению, но при этом позволяет больше данных грузить в батч

- `collate_fn` -- коллатор, которые передается в `torch.utils.data.DataLoader`, реализует логику добавление паддингов к элементов батча

- 